{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um projeto de *machine learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivos:**\n",
    "\n",
    "- Aprender sobre o processo CRISP-DM;\n",
    "- Aplicar o CRISP-DM a um projeto real de *machine learning*;\n",
    "- Praticar análise exploratória;\n",
    "- Construir *pipelines* de processamento de dados em scikit-learn;\n",
    "- Entender o processo de construção, escolha e avaliação de modelos de *machine learning*;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O processo CRISP-DM\n",
    "\n",
    "CRISP-DM: CRoss-Industry Standard Process for Data Mining\n",
    "\n",
    "***Atividade***: Leia o artigo \"The CRISP-DM Model: The New Blueprint for Data Mining\" (arquivo [`crisp-dm.pdf`](../resources/crisp-dm.pdf)) e responda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O CRISP-DM é um processo de gerenciamento de equipes ou de estruturação de projetos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "CRISP-DM é um método de estruturação de projetos de \"Data Mining\", um nome antigo para o que hoje chamamos geralmente de \"Ciência dos Dados\". O método CRISP-DM especifica quais atividades devem acontecer em um projeto típico de ciência dos dados, sem especificar como a equipe de trabalho deve se organizar - e.g. SCRUM.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Construa uma explicação do ciclo do CRISP-DM conforme visto na figura abaixo. Preste atenção especial para o fato de que temos setas bidirecionais entre \"Business Understanding\" e \"Data Understanding\", e entre \"Data Preparation\" e \"Modeling\" - porque os autores se deram ao trabalho de fazer isso?\n",
    "\n",
    "![CRISP-DM diagram](../resources/crisp-dm.png)\n",
    "\n",
    "Fonte: Kenneth Jensen, CC BY-SA 3.0 <https://creativecommons.org/licenses/by-sa/3.0>, via Wikimedia Commons. https://commons.wikimedia.org/wiki/File:CRISP-DM_Process_Diagram.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Podemos observar alguns elementos sugestivos na figura acima:\n",
    "\n",
    "- No centro da figura temos uma imagem representando a base de dados. Isto indica a proeminência dos dados - sua disponibilidade, seu entendimento, questões éticas e de segurança, etc - em todas as fases do projeto de *data science*.\n",
    "\n",
    "- Na região externa da figura temos um grande círculo indicando:\n",
    "\n",
    "    - A direção do fluxo do projeto;\n",
    "\n",
    "    - O fato de que um projeto de ciência dos dados é feito de modo iterativo, onde as lições aprendidas em um ciclo do projeto são incorporadas à próxima iteração. Desta forma, existe um aperfeiçoamento contínuo do projeto, e mesmo uma reavaliação periódica de seus objetivos. Tal filosofia de desenvolvimento de projetos se assemelha ao desenvolvimento ágil de software, onde reconhece-se primordialmente que projetos desta natureza (seja desenvolvimento de software ou ciência dos dados) possuem uma grande incerteza inicial em relação aos objetivos e ao potencial do projeto, e que portanto a construção de valor tem que ser progressiva.\n",
    "\n",
    "- Na região intermediária da figura existe um diagrama de blocos que representa a sequência de etapas do ciclo de projeto, com destaque para três fases:\n",
    "\n",
    "    - A interação $\\text{\"Business Understanding\"} \\rightleftarrows \\text{\"Data Understanding\"}$: Indica a importância da construção de conhecimento compartilhado entre profissionais complementares:\n",
    "\n",
    "        - O especialista de negócios: entende o contexto do problema à qual o projeto se destina, e auxilia na concepção de objetivos que agregam valor ao negócio. Transfere conhecimento de contexto do problema e da natureza da origem dos dados ao especialista de dados. Ajusta seu próprio entendimento do potencial do projeto ao receber do especialista de dados mais conhecimento sobre a real informação contida nos dados, suas limitações e potenciais;\n",
    "\n",
    "        - O especialista de dados: Tal qual um arquiteto que traduz os desejos do cliente em algo factível frente às limitações do mundo real, o especialista de dados explora os dados junto com o especialista de negócios para construir um entendimento conjunto destes dados, e do que se pode obter destes (insights, modelagem preditiva, etc)\n",
    "\n",
    "        Nesta fase constrói-se o conjunto de objetivos do ciclo atual de desenvolvimento.\n",
    "\n",
    "    - A interação $\\text{\"Data preparation\"} \\rightleftarrows \\text{\"Modeling\"}$: \n",
    "    \n",
    "        Preparação e modelagem de dados não são atividades estanques. Cada modelo requer uma preparação diferente, e a gama de modelos existentes é muito grande. Ademais, ao experimentar com o uso de um modelo pode-se descobrir que pode ser vantajoso processar os dados de maneira diferente, para um mesmo modelo. Esta manipulação de processamento e modelagem é um processo criativo, porém sujeito à rigorosa avaliação. Realizam-se iterações nesta fase até que um desempenho satisfatório seja atingido - ou que se estabeleça que talvez um desempenho satisfatório não seja possível, e que a fase de \"Evaluation\" a seguir deverá provavelmente enviar o fluxo de projeto para o ponto de partida.\n",
    "\n",
    "        Nesta fase escolhe-se a melhor combinação pré-processamento/modelagem para o conjunto de dados de <span style=\"color:red;font-weight:bold\">TREINO</style>.\n",
    "\n",
    "    - O ponto de decisão \"Evaluate\" e os fluxos resultantes:\n",
    "\n",
    "        Neste ponto devemos tomar a pipeline de processamento e modelagem advinda do processo anterior e avaliar seu desempenho em um conjunto de dados de <span style=\"color:red;font-weight:bold\">TESTE</style>.\n",
    "\n",
    "        Se o desempenho de <span style=\"color:red;font-weight:bold>teste</span> for satisfatório podemos seguir para a fase \"Deployment\". Nesta fase iremos produzir um artefato deste ciclo de trabalho que traga valor para o negócio, similar ao \"minimum-viable-product\" do desenvolvimento ágil. Este artefato pode ser um relatório com insights e lições aprendidas neste ciclo de análise dos dados, um novo conjunto de código e de parâmetros de modelo a ser utilizado em uma aplicação (e.g. em um microsserviço de predição que faz parte de um produto online da empresa), etc.\n",
    "\n",
    "        Se o desempenho de <span style=\"color:red;font-weight:bold\">teste</span> não for satisfatório, devemos tomar as lições aprendidas e retornar ao sub-ciclo $\\text{\"Business Understanding\"} \\rightleftarrows \\text{\"Data Understanding\"}$ e levar esse novo conhecimento em consideração para melhorar o entendimento global do problema e recomeçar a modelagem com maiores chances de sucesso.\n",
    "\n",
    "Após o \"Deployment\" em um ciclo bem-sucedido de projeto, devemos decidir se o projeto chegou a um estado final (seja um estado satisfatório ou porque houve uma decisão executiva de parar o projeto). Caso o projeto ainda deva continuar, iniciamos um novo ciclo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Segundo o artigo, qual a porcentagem do tempo que se gasta, tipicamente, em cada uma das fases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No artigo, página 15, segunda coluna, segundo parágrafo, lê-se:\n",
    "\n",
    "> Generally accepted industry timeline standards are: $50$ to $70$\n",
    "> percent of the time and effort in a data mining project involves\n",
    "> the Data Preparation Phase; $20$ to $30$ percent involves the Data\n",
    "> Understanding Phase; only $10$ to $20$ percent is spent in each of\n",
    "> the Modeling, Evaluation, and Business Understanding Phases;\n",
    "> and $5$ to $10$ percent is spent in the Deployment Planning Phase.\n",
    "\n",
    "Essas frações não somam 100% porque existe sobreposição entre as fases:\n",
    "\n",
    "- \"Business Understanding\" e \"Data Understanding\": duração total de $20\\%$ a $30\\%$\n",
    "- \"Data Preparation\" e \"Modeling\": duração total de $50\\%$ a $70\\%$\n",
    "- \"Evaluation\" e \"Deployment\": $10\\%$ a $20\\%$\n",
    "\n",
    "Somando-se as durações médias das fases temos $25\\% + 60\\% + 15\\%$ totalizando $100\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *California Housing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trabalhar com um *dataset* de imóveis residenciais da Califórnia nos anos 1990."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd().parents[1] / 'datasets' / 'housing'\n",
    "print(f'Saving data to {DATA_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "def fetch_housing_data(data_dir: Path) -> None:\n",
    "    '''Downloads the California Housing Prices dataset.\n",
    "\n",
    "    Downloads the California Housing Prices dataset from Aurelien Geron's\n",
    "    GitHub repository and saves it to the specified directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir: The directory to which the dataset will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    if not data_dir.exists():\n",
    "        data_dir.mkdir(parents=True)\n",
    "\n",
    "    # Fetch the housing data.\n",
    "    HOUSING_URL = ('https://raw.githubusercontent.com/ageron/handson-ml2/'\n",
    "                   'master/datasets/housing/housing.tgz')\n",
    "    tgz_path = data_dir / 'housing.tgz'\n",
    "    request.urlretrieve(HOUSING_URL, tgz_path)\n",
    "\n",
    "    # Extract the housing data.\n",
    "    with tarfile.open(tgz_path) as housing_tgz:\n",
    "        housing_tgz.extractall(path=data_dir, filter='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_housing_data(data_dir: Path) -> pd.DataFrame:\n",
    "    '''Loads the California Housing Prices dataset.\n",
    "\n",
    "    Loads the California Housing Prices dataset from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir: The directory from which the dataset will be loaded.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the California Housing Prices dataset.\n",
    "    '''\n",
    "    csv_path = data_dir / 'housing.csv'\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_housing_data(DATA_DIR)\n",
    "\n",
    "print(f'O dataset tem {data.shape[0]} linhas e {data.shape[1]} colunas.')\n",
    "print('As colunas são:')\n",
    "for column_name in data.columns:\n",
    "    print(f'- \"{column_name}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendimento do negócio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses dados representam informações censitárias acerca de *distritos* residenciais no estado da California na década de 1990.\n",
    "\n",
    "Atividade: Baseado nos nomes das colunas, você conseguiria escrever o significado de cada coluna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta: não muito bem.\n",
    "\n",
    "Consultando o livro-texto da disciplina, capítulo 2, aprendemos que esses dados se referem aos distritos (conforme escrito no enunciado) e, portanto, são um pouco estranhos. Provavelmente significam, para cada distrito, o seguinte:\n",
    "\n",
    "- `longitude`: a longitude do centro;\n",
    "- `latitude`: a latitude do centro;\n",
    "- `housing_median_age`: a idade mediana dos imóveis;\n",
    "- `total_rooms`: essa é estranha, é a quantidade **total** de cômodos no distrito. Ou seja, a soma do número de cômodos de todos os imóveis;\n",
    "- `total_bedrooms`: a soma do número de *quartos* de todos os imóveis;\n",
    "- `population`: quantas pessoas moram no distrito;\n",
    "- `households`: número de imóveis;\n",
    "- `median_income`: renda mediana dos moradores do distrito;\n",
    "- `median_house_value`: o valor mediano dos imóveis do distrito. Esta é a nossa variável a ser predita;\n",
    "- `ocean_proximity`: só pelo nome é difícil saber a natureza exata desta variável. Trata-se de uma variável *categórica* indicando o \"status\" do distrito em relação à sua proximidade com o oceano Pacífico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividade: Escreva o objetivo de negócios deste projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso objetivo é prever o valor mediano dos imóveis de um distrito residencial da Califórnia, baseado em uma série de atributos deste conforme visto acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo da análise exploratória é \"conhecer\" os dados:\n",
    "\n",
    "- Qual a distribuição de cada *feature*?\n",
    "\n",
    "- Qual a natureza de cada *feature*?\n",
    "\n",
    "    - Unidade de medida\n",
    "\n",
    "    - Se é estritamente positiva ou se pode ser positiva ou negativa\n",
    "\n",
    "    - Para que serve?\n",
    "\n",
    "- Quais e como são as distribuições conjuntas de *features*? Em particular, como as *features* se relacionam com o *target*?\n",
    "\n",
    "- Existem anomalias e erros?\n",
    "\n",
    "    - Dados faltantes\n",
    "\n",
    "    - \"Saturação\" de dados\n",
    "\n",
    "    - Outliers\n",
    "\n",
    "    - Desbalanceamento de classes\n",
    "\n",
    "    - Dados duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise exploratória: antes ou depois da separação treino-teste?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante o processo de modelagem vamos dividir os dados em dois conjuntos: \"dados de treino\" e \"dados de teste\". Devemos treinar nossos modelos com o conjunto de dados de treino, e avaliar seu desempenho no conjunto de teste, para que não nos enganemos com desempenhos preditivos excelentes no conjunto de treino e que não se reproduzem no conjunto de teste!\n",
    "\n",
    "Atividade: Como se chama o fenômeno no qual temos um excelente desempenho no conjunto de treino e um desempenho bem menor no conjunto de teste?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><span style=\"color:red;font-weight:bold;font-size:30px\">OVERFITTING!</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando devemos fazer a análise exploratória?\n",
    "\n",
    "- Antes da separação treino-teste, ou seja, no conjunto de dados completo?\n",
    "\n",
    "- Depois da separação treino-teste, ou seja, usando apenas o conjunto de dados de treino?\n",
    "\n",
    "Esta é uma pergunta difícil de responder.\n",
    "\n",
    "- Analisar antes da separação:\n",
    "\n",
    "    - Vantagens: todo o conjunto de dados de exemplo que foi coletado está á nossa disposição para estudo, o que torna mais fácil a detecção de anomalias raras, como outliers ou a ocorrência de categorias raras em *features* categóricas.\n",
    "\n",
    "    - Desvantagens: corremos o risco de \"data snooping\" (\"bisbilhotar\" os dados), onde acabamos por aprender algo sobre os dados que pode impactar de modo \"injusto\" nossa modelagem - é como se estivéssemos \"overfittando\" sem querer!\n",
    "\n",
    "- Analisar depois da separação:\n",
    "\n",
    "    - Vantagens: reduz o risco de \"data snooping\"\n",
    "\n",
    "    - Desvantagens: podemos não perceber anomalias e erros raros nos dados, que podem impactar nossa modelagem de uma forma que é difícil de identificar.\n",
    "\n",
    "O que fazer então? Em geral, queremos balancear o risco de \"data snooping\" com o risco de não entender os detalhes mais finos e raros dos dados. Portando a recomendação é fazer análises exploratórias antes e depois da separação, com objetivos diferentes:\n",
    "\n",
    "- Análise exploratória antes da separação: faça apenas análises globais e simples, para checar a sanidade dos dados e realizar filtragens simples. Evite análises que conectem as *features* com o *target*.\n",
    "\n",
    "- Análise exploratória depois da separação: você está livre para explorar o que quiser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer uma primeira análise dos dados, apenas para checar a integridade destes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividade: Acompanhe o desenvolvimento da análise exploratória a ser feito pelo professor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Nossa exploração terá três fases:\n",
    "\n",
    "- Análise exploratória preliminar\n",
    "- Separação treino-teste\n",
    "- Análise exploratória complementar\n",
    "\n",
    "É importante distinguir a análise exploratória realizada antes da separação de dados em conjuntos de treino e teste, daquela posterior a esta separação, para evitar o *\"data snooping\"* descrito acima.\n",
    "\n",
    "#### Análise exploratória\n",
    "\n",
    "Nesta fase vamos conhecer a natureza dos dados sem explorar suas interrelações, em especial não vamos explorar a conexão entre as *features* e o *target*.\n",
    "\n",
    "Vamos proceder da seguinte forma:\n",
    "\n",
    "<table>\n",
    "\n",
    "<tr>\n",
    "<th> Etapa </th>\n",
    "<th> Objetivos </th>\n",
    "<th> Ferramentas </th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "\n",
    "<td>\n",
    "    Uma análise global do volume de dados\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "    <ul>\n",
    "    <li> Quais são as <em>features</em>?</li>\n",
    "    <li> Quem é o <em>target</em>?</li>\n",
    "    <li> Quais variáveis são contínuas e quais são categóricas?</li>\n",
    "    <li> Existem dados faltantes? </li>\n",
    "    <li> Existem dados duplicados? </li>\n",
    "    </ul>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "    <div>\n",
    "    <ul>\n",
    "    <li> Número de linhas e colunas </li>\n",
    "    <li> Tipo de dados de cada coluna </li>\n",
    "    <li> Remoção de linhas duplicadas <em>se isso realmente for um erro</em> </li>\n",
    "    </ul>\n",
    "    </div>\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "\n",
    "<td>\n",
    "    Uma primeira análise da natureza das features\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "    <ul>\n",
    "    <li> Qual a unidade de medida de cada variável? </li>\n",
    "    <li> Existem anomalias? \n",
    "        <ul>\n",
    "            <li> <em>outliers</em> </li>\n",
    "            <li> erros grosseiros </li>\n",
    "            <li> <em>spikes</em> </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li> Para cada variável contínua\n",
    "        <ul>\n",
    "            <li> Simétrica? </li>\n",
    "            <li> Estritamente positiva/negativa? </li>\n",
    "            <li> Unimodal / multimodal? </li>\n",
    "            <li> Cauda longa à direita/esquerda? </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li> Para cada variável categórica\n",
    "        <ul>\n",
    "            <li>Categorias raras?</li>\n",
    "            <li>Categorias dominantes?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    </ul>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "    <ul>\n",
    "    <li>Medidas descritivas de posição e espalhamento</li>\n",
    "    <li>Histogramas</li>\n",
    "    <li>Tabelas de frequência</li>\n",
    "    <li>Gráficos de barra</li>\n",
    "    </ul>\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos conferir os tipos de dados espiando as primeiras linhas do *dataset*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E vamos verificar quantos exemplos temos, e qual o tipo de dados identificado pelo Pandas para cada coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas do tipo `float64` são todas contínuas neste exemplo. Isso nem sempre é verdade: pode ser que tenhamos uma variável categórica que foi lida como `float64` por engano! Sempre verifique a natureza das suas variáveis.\n",
    "\n",
    "Em teoria, não é estritamente correto dizer que essas variáveis `float64` são perfeitamente contínuas. Na verdade, a maioria delas é discreta, pois trata-se de contagens ou de idade inteira: `housing_median_age`, `total_rooms`, `total_bedrooms`, `population`, `households`. A decisão de convertê-las para inteiros ou mantê-las como números reais é dependente de aplicação. Para nós, neste projeto, não vai fazer diferença.\n",
    "\n",
    "A feature `ocean_proximity` é do tipo `object`, que é o tipo de dados que o Pandas associa a qualquer coisa que não seja um número."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vamos registrar as descrições e unidades de medida de cada variável:\n",
    "\n",
    "| Variável             | Unidade de medida  | Descrição                                         |\n",
    "|----------------------|--------------------|---------------------------------------------------|\n",
    "| `longitude`          | graus              | a longitude do centro                             |\n",
    "| `latitude`           | graus              | a latitude do centro                              |\n",
    "| `housing_median_age` | anos               | a idade mediana dos imóveis                       |\n",
    "| `total_rooms`        | n/a - contagem     | soma do número de cômodos de todos os imóveis     |\n",
    "| `total_bedrooms`     | n/a - contagem     | a soma do número de *quartos* de todos os imóveis |\n",
    "| `population`         | n/a - contagem     | quantas pessoas moram no distrito                 |\n",
    "| `households`         | n/a - contagem     | número de imóveis                                 |\n",
    "| `median_income`      | US$ $\\times 10000$ | renda mediana dos moradores do distrito           |\n",
    "| `median_house_value` | US$                | o valor mediano dos imóveis do distrito           |\n",
    "| `ocean_proximity`    | n/a - categoria    | categoria de proximidade com o oceano Pacífico    |\n",
    "\n",
    "As informações aqui foram obtidas do livro-texto da disciplina, capítulo 2, que está servindo de \"Business Expert\" para a gente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_dups = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_dups.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *dataset* sem linhas duplicadas tem o mesmo tamanho do *dataset* original, indicando que não existiam linhas duplicadas de qualquer forma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise preliminar das features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar as medidas descritivas de cada feature, a começar pelas variáveis contínuas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando a tabela fica muito longa horizontalmente e curta verticalmente, tente \"transpor\" a tabela para ver se fica melhor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number').describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhorou. Agora limite o número de casas decimais para ficar mais fácil ainda de observar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number').describe().round(2).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos o seguinte:\n",
    "\n",
    "- Todas as colunas possuem $20640$ itens não-nulos (\"count\"), exceto pela coluna `total_bedrooms` que tem valores faltantes. Vamos discutir medidas para lidar com isso em breve.\n",
    "\n",
    "- Latitude e Longitude ficam em torno de $-120\\degree$ e $36\\degree$, correspondendo à localização geral da Califórnia.\n",
    "\n",
    "<center>\n",
    "<img \n",
    "    src=\"../resources/california_location.png\"\n",
    "    alt=\"Snapshot of California showing latitude and longitude\"\n",
    "    width=\"400\"\n",
    "/>\n",
    "</center>\n",
    "\n",
    "- Fora latitude e longitude, as features são todas estritamente positivas, tem valor mínimo teórico de zero, e tem uma variabilidade muito alta! Podemos analisar a magnitude da variabilidade de cada feature em relação à sua própria média, obtendo desta forma um valor normalizado de variação chamado *coeficiente de variação*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coefficient_of_variation(data: pd.DataFrame) -> pd.Series:\n",
    "    '''Computes the coefficient of variation for each column in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data: A pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A pandas Series containing the coefficient of variation for each column\n",
    "        in the input DataFrame.\n",
    "    '''\n",
    "    stats = data \\\n",
    "        .select_dtypes(include='number') \\\n",
    "        .describe() \\\n",
    "        .transpose() \\\n",
    "        .drop(['longitude', 'latitude'], axis=0)\n",
    "    CV = stats['std'] / stats['mean']\n",
    "    CV.rename('Coefficient of Variation', inplace=True)\n",
    "    return CV\n",
    "\n",
    "print(compute_coefficient_of_variation(data).round(2).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature            |   Coefficient of Variation |\n",
    "|:-------------------|---------------------------:|\n",
    "| housing_median_age |                       0.44 |\n",
    "| total_rooms        |                       0.83 |\n",
    "| total_bedrooms     |                       0.78 |\n",
    "| population         |                       0.79 |\n",
    "| households         |                       0.77 |\n",
    "| median_income      |                       0.49 |\n",
    "| median_house_value |                       0.56 |\n",
    "\n",
    "Podemos observar que as medidas de desvio padrão, quando normalizadas pelo valor da média (ou seja, o coeficiente de variação), são valores entre $44\\%$ e $83\\%$, indicando que existe muita diferença entre os distritos da Califórnia em todos esses atributos. \n",
    "\n",
    "E daí? Bem, esta observação pode indicar alternativas de modelagem dos dados. Talvez existam classes intrínsecas de distritos californianos, e que modelar essa possível *variável latente* pode ser útil para melhorar o desempenho do modelo. Talvez tenhamos *outliers* e cauda longa, que estão enviesando o cálculo do desvio padrão. De qualquer modo, indica que devemos prestar mais atenção na distribuição dos dados.\n",
    "\n",
    "Vamos então estudar a distribuição de cada variável com histogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Regra prática: número de bins = sqrt(número de amostras)\n",
    "n_bins = np.floor(np.sqrt(data.shape[0])).astype(int).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.select_dtypes(include='number').hist(bins=n_bins, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos o seguinte:\n",
    "\n",
    "**Latitude e longitude**\n",
    "\n",
    "Estão flutuando de um jeito dificil de entender. Mas isso é esperado - basta plotar os dados e compará-los á um mapa da California:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geo_pop():\n",
    "    '''Plots the geographical distribution of the population in California.'''\n",
    "    # Ordena os dados por população. É um truque para evitar que pontos\n",
    "    # sobrepostos ocultem outros pontos. Assim, os pontos com populações\n",
    "    # maiores são plotados por último.\n",
    "    sorted_data = data.sort_values(by='population', ascending=True)\n",
    "\n",
    "    longitude = sorted_data['longitude']\n",
    "    latitude = sorted_data['latitude']\n",
    "    population = sorted_data['population']\n",
    "\n",
    "    # Ajusta a razão de aspecto para compensar a distorção da projeção.\n",
    "    aspect_ratio = 1 / np.cos(np.mean(latitude) * np.pi / 180)\n",
    "\n",
    "    img = plt.imread(Path.cwd().parent / 'resources' / 'california.png')\n",
    "\n",
    "    plt.figure(figsize=(7, 10))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.scatter(\n",
    "        longitude,\n",
    "        latitude,\n",
    "        alpha=0.5,\n",
    "        s=population / 200,\n",
    "        c=population,\n",
    "        cmap='viridis',\n",
    "    )\n",
    "    plt.colorbar(label='População')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.gca().set_aspect(aspect_ratio)\n",
    "    plt.title('Distribuição Geográfica da População na Califórnia')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_geo_pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente a população californiana se distribui heterogeneamente, como se espera de qualquer população."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtragem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividade: Baseado no que aprendemos na análise exploratória, escreva um código para filtrar o *dataset*. Não modifique as colunas, apenas aceite ou rejeite cada linha de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salve o resultado do processamento na forma de um arquivo \"Parquet\": https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_parquet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos dados e Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
