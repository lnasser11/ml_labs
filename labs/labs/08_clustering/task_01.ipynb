{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo de k-médias (k-means) é um dos algoritmos mais simples de clustering. A idéia básica é a seguinte:\n",
    "\n",
    "- Escolhe-se, a priori, um número $k$ de clusters. A escolha de um bom número de clusters é um problema não resolvido em machine learning, mas com algum conhecimento do domínio de aplicação podemos fazer boas escolhas aqui.\n",
    "\n",
    "- Cada cluster é caracterizado por um valor de centróide (daí o nome 'k-means').\n",
    "\n",
    "- Cada ponto do conjunto é atribuido ao cluster de seu centróide mais próximo.\n",
    "\n",
    "Estas características do modelo k-means praticamente definem o algoritmo:\n",
    "\n",
    "1. Inicialize os $k$ centróides aleatoriamente. Uma abordagem bastante popular é escolher $k$ pontos ao acaso dentro do dataset.\n",
    "\n",
    "2. Enquanto não convergiu:\n",
    "\n",
    "    2.1. Associe cada ponto ao seu centroide mais próximo\n",
    "    \n",
    "    2.2. Atualize cada centróide como sendo o ponto médio dos pontos a ele atribuidos.\n",
    "\n",
    "O código abaixo demonstra a evolução dos centróides de um dataset aleatório com 3 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Note que estamos ignorando os labels y - este é um problema de clustering,\n",
    "# não de classificação.\n",
    "X, _ = make_blobs(\n",
    "    n_samples=200,\n",
    "    centers=3,\n",
    "    n_features=2,\n",
    "    cluster_std=2.5,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "num_points = X.shape[0]\n",
    "\n",
    "# Seleciona os centroides iniciais através de sorteio de pontos do dataset.\n",
    "np.random.seed(RANDOM_SEED)\n",
    "idx = np.random.choice(\n",
    "    num_points,\n",
    "    size=(k,),\n",
    "    replace=False,\n",
    ")\n",
    "C = X[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'lightgreen', 'blue']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora associa cada ponto do dataset ao seu centroide mais proximo.\n",
    "def distancia(a, b):\n",
    "    return np.sqrt(np.sum((a - b)**2))\n",
    "\n",
    "\n",
    "def acha_mais_proximo(x, C):\n",
    "    num_centroides = C.shape[0]\n",
    "    mais_proximo = 0\n",
    "    dist_mais_proximo = distancia(x, C[0, :])\n",
    "    for j in range(1, num_centroides):\n",
    "        dist = distancia(x, C[j, :])\n",
    "        if dist < dist_mais_proximo:\n",
    "            dist_mais_proximo = dist\n",
    "            mais_proximo = j\n",
    "    return mais_proximo\n",
    "\n",
    "\n",
    "def atualiza_cluster(X, C):\n",
    "    cluster = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        cluster[i] = acha_mais_proximo(X[i, :], C)\n",
    "    return cluster\n",
    "\n",
    "\n",
    "cluster = atualiza_cluster(X, C)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(k):\n",
    "    idx = cluster == i  # Seleciona pontos deste cluster.\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=colors[i],\n",
    "        marker='x',\n",
    "        alpha=0.8,\n",
    "    )\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalcula os centroides.\n",
    "def recalcula_centroides(X, cluster, k):\n",
    "    dims = X.shape[1]\n",
    "    C = np.zeros((k, dims))\n",
    "    for i in range(k):\n",
    "        idx = cluster == i\n",
    "        C[i, :] = X[idx, :].mean(axis=0)\n",
    "    return C\n",
    "\n",
    "\n",
    "C_novo = recalcula_centroides(X, cluster, k)\n",
    "\n",
    "print('Antigo é bolinha, novo é diamante.')\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(k):\n",
    "    idx = cluster == i\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=colors[i],\n",
    "        marker='x',\n",
    "        alpha=0.8,\n",
    "    )\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "plt.scatter(\n",
    "    C_novo[:, 0],\n",
    "    C_novo[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    "    marker='d',\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por fim, o algoritmo k-means repete o processo várias vezes.\n",
    "def max_dist_pontos(C, C_novo):\n",
    "    max_dist = 0.0\n",
    "    for i in range(C.shape[0]):\n",
    "        dist = distancia(C[i, :], C_novo[i, :])\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "    return max_dist\n",
    "\n",
    "\n",
    "def k_means(X, k, C_init=None, max_iter=10, eps=1e-3):\n",
    "    if C_init is None:\n",
    "        # Seleciona os centroides iniciais.\n",
    "        idx = np.random.choice(\n",
    "            X.shape[0],\n",
    "            size=(k,),\n",
    "            replace=False,\n",
    "        )\n",
    "        C = X[idx, :]\n",
    "    else:\n",
    "        C = C_init\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        cluster = atualiza_cluster(X, C)\n",
    "        C_novo = recalcula_centroides(X, cluster, k)\n",
    "        max_dist = max_dist_pontos(C, C_novo)\n",
    "        C = C_novo\n",
    "        if max_dist < eps:\n",
    "            break\n",
    "    return C\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "C = k_means(X, k)\n",
    "\n",
    "cluster = atualiza_cluster(X, C)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(k):\n",
    "    idx = cluster == i\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=colors[i],\n",
    "        marker='x',\n",
    "        alpha=0.8,\n",
    "    )\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que o k-means convergiu, mas não para a clusterização esperada! Vamos repetir o processo com pontos iniciais mais razoáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([[-7, -7], [5, 0], [-3, 10]])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ver se o algoritmo converge para algo mais razoavel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "C = k_means(X, k, C_init=C)\n",
    "\n",
    "cluster = atualiza_cluster(X, C)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(k):\n",
    "    idx = cluster == i\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=colors[i],\n",
    "        marker='x',\n",
    "        alpha=0.8,\n",
    "    )\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, parece que agora funcionou..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade:**\n",
    "\n",
    "Considere a situação abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = X.copy()\n",
    "Xs[:, 1] *= 50\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    Xs[:, 0],\n",
    "    Xs[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    "    alpha=0.8,\n",
    ")\n",
    "# plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aplique o algoritmo k-means para clusterizar este dataset, e mostre o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Este clustering ficou bom? Explique o que aconteceu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qual a complexidade de cada passo do algoritmo k-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade:**\n",
    "\n",
    "Implemente o clustering do dataset original usando o scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean shift clustering\n",
    "\n",
    "Observamos que geralmente os clusters tem uma densidade de pontos maior em seu centro do que na periferia. Agora imagine um ponto qualquer do conjunto de dados: como a vizinhança deste ponto se parece? Pela propriedade anterior, podemos imaginar que existe uma densidade maior de pontos na vizinhança de um ponto dado na direção do centro do cluster. Se calcularmos o ponto médio dos pontos desta vizinhança, nos aproximamos do centro do cluster.\n",
    "\n",
    "Essa é a idéia básica do algoritmo \"mean shift clustering\". Vamos explorar este conceito. Primeiramente vamos sortear pontos ao acaso do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seed_pts = 20\n",
    "\n",
    "# Seleciona os pontos iniciais.\n",
    "np.random.seed(RANDOM_SEED)\n",
    "idx = np.random.choice(\n",
    "    X.shape[0],\n",
    "    size=(num_seed_pts,),\n",
    "    replace=False,\n",
    ")\n",
    "C = X[idx, :]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c='red',\n",
    "    s=50,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora procedemos da seguinte forma: para cada ponto de referência em C, vamos determinar a posição média de seus vizinhos (dentro de um raio dado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 5\n",
    "\n",
    "\n",
    "def atualiza_pontos(X, C, R):\n",
    "    C_novo = np.zeros(C.shape)\n",
    "    n_novo = np.zeros(C.shape[0])\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if distancia(X[j, :], C[i, :]) < R:\n",
    "                C_novo[i, :] += X[j, :]\n",
    "                n_novo[i] += 1.0\n",
    "        C_novo[i, :] /= n_novo[i]\n",
    "    return C_novo\n",
    "\n",
    "\n",
    "C_novo = atualiza_pontos(X, C, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c='red',\n",
    "    s=50,\n",
    ")\n",
    "plt.scatter(\n",
    "    C_novo[:, 0],\n",
    "    C_novo[:, 1],\n",
    "    c='blue',\n",
    "    s=50,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os pontos atualizados migraram para o centro dos clusters! Vamos agora agrupar pontos que estão muito próximos entre si, pois não faz sentido manter dois pontos idênticos neste conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimina_similares(C, eps=1e-3):\n",
    "    C_novo = C.copy()\n",
    "    i = 0\n",
    "    while i < C_novo.shape[0]:\n",
    "        j = i + 1\n",
    "        while j < C_novo.shape[0]:\n",
    "            if distancia(C_novo[i, :], C_novo[j, :]) < eps:\n",
    "                C_novo = np.delete(C_novo, (j), axis=0)\n",
    "            else:\n",
    "                j += 1\n",
    "        i += 1\n",
    "    return C_novo\n",
    "\n",
    "\n",
    "C = elimina_similares(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    c='black',\n",
    "    marker='x',\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.scatter(\n",
    "    C[:, 0],\n",
    "    C[:, 1],\n",
    "    c='red',\n",
    "    s=50,\n",
    ")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos continuar este processo até que o algoritmo convirja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shift(\n",
    "    X,\n",
    "    C_init=None,\n",
    "    k=10,\n",
    "    max_iter=30,\n",
    "    eps_elimina=1e-9,\n",
    "    eps_para=1e-9,\n",
    "):\n",
    "    if C_init is None:\n",
    "        # Seleciona os centroides iniciais.\n",
    "        idx = np.random.choice(\n",
    "            X.shape[0],\n",
    "            size=(k,),\n",
    "            replace=False,\n",
    "        )\n",
    "        C = X[idx, :]\n",
    "    else:\n",
    "        C = C_init\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        C_novo = atualiza_pontos(X, C, R)\n",
    "        max_dist = max_dist_pontos(C, C_novo)\n",
    "        C = C_novo\n",
    "        if max_dist < eps_para:\n",
    "            break\n",
    "        C = elimina_similares(C, eps=eps_elimina)\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "C_mf = mean_shift(X, k=20, eps_elimina=0.5, eps_para=1e-6)\n",
    "print(C_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c='black', marker='x', alpha=0.8)\n",
    "plt.scatter(C_mf[:, 0], C_mf[:, 1], c='red', s=50)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente podemos associar cada amostra ao seu ponto representativo mais próximo, como no caso do k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = atualiza_cluster(X, C_mf)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "for i in range(C_mf.shape[0]):\n",
    "    idx = cluster == i\n",
    "    plt.scatter(\n",
    "        X[idx, 0],\n",
    "        X[idx, 1],\n",
    "        c=colors[i],\n",
    "        marker='x',\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "plt.scatter(\n",
    "    C_mf[:, 0],\n",
    "    C_mf[:, 1],\n",
    "    c=colors,\n",
    "    s=200,\n",
    ")\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade:**\n",
    "\n",
    "Implemente o clustering do dataset original usando scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros métodos\n",
    "\n",
    "Existem vários outros métodos de clustering, como DBSCAN, clustering hierárquico aglomerativo e modelos de mistura de Gaussianas, que valem a pena conhecer. Mas para uma aula introdutória de clustering, está bom.\n",
    "\n",
    "**Atividades:**\n",
    "\n",
    "- Explique o funcionamento do DBSCAN\n",
    "- Explique o funcionamento do clustering hierárquico. Compare com árvores de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apendice: clustering de palavras usando word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_doc(doc):\n",
    "\n",
    "    def normalize_string(s):\n",
    "        table_punct = str.maketrans({key: None for key in string.punctuation})\n",
    "        return s.strip().lower().translate(table_punct)\n",
    "\n",
    "    return ' '.join([normalize_string(line) for line in doc.split('\\n')])\n",
    "\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "\n",
    "sentences = np.array(\n",
    "    [process_doc(doc).split() for doc in data.data],\n",
    "    dtype=object,\n",
    ")\n",
    "print(sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model = Word2Vec(sentences, vector_size=300, min_count=50)\n",
    "words = model.wv.index_to_key\n",
    "X_words = model.wv[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_SEED)\n",
    "result = kmeans.fit_predict(X_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a, b):\n",
    "    return a.dot(b) / np.sqrt(a.dot(a) * b.dot(b))\n",
    "\n",
    "\n",
    "words_per_cluster = [[] for _ in range(n_clusters)]\n",
    "\n",
    "for w, x, k in zip(words, X_words, result):\n",
    "    dist = 1 - cosine(x, kmeans.cluster_centers_[k])\n",
    "    words_per_cluster[k].append((dist, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from pprint import pprint\n",
    "\n",
    "n_words = 20\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    print(f'Cluster {i}')\n",
    "    print('-----')\n",
    "    pprint([res[1] for res in heapq.nsmallest(n_words, words_per_cluster[i])])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
